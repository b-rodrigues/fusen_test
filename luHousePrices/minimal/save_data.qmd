---
title: "Nominal house prices data in Luxembourg"
author: "Bruno Rodrigues"
date: today
---

```{r development, include=FALSE}
library(dplyr)
library(ggplot2)
library(janitor)
library(purrr)
library(readxl)
library(rvest)
library(stringr)
library(testthat)
```


This data is downloaded from the "Observatoire de l'habitat":


```{r function-define_imports}
#' define_imports This function lists the needed dependencies
#'
#' @importFrom readxl excel_sheets read_excel
#' @importFrom janitor clean_names
#' @importFrom dplyr mutate select starts_with across filter rename full_join
#' @importFrom purrr map_dfr pluck
#' @importFrom stringr str_trim
#' @importFrom ggplot2 ggplot geom_line aes
#' @importFrom rvest read_html html_table
#' @return Nothing; simply used for NAMESPACE creation
NULL
```

```{r function-get_raw_data}
#' get_raw_data Gets raw nominal house price data from LU Open Data Portal
#'
#' @param url Optional: Persistent url to the data
#' @return A data frame
#' @export
get_raw_data <- function(url = "https://data.public.lu/fr/datasets/r/1d20f982-57e1-4ae2-a278-dc78c88c21dc"){
  #raw_data <- tempfile(fileext = ".xlsx")

  #download.file(url, raw_data)

  raw_data <- "c:/Users/LLP685/Downloads/vente-appartement-2010-2021.xlsx"
  sheets <- excel_sheets(raw_data)

  read_clean <- function(..., sheet){
    read_excel(..., sheet = sheet) %>%
      mutate(year = sheet)
  }

  raw_data <- map_dfr(sheets,
                      ~read_clean(raw_data,
                                  skip = 10,
                                  sheet = .)) %>%
    clean_names()

  raw_data %>%
    rename(locality = commune,
           n_offers = nombre_doffres,
           average_price_nominal_euros = prix_moyen_annonce_en_courant,
           average_price_m2_nominal_euros = prix_moyen_annonce_au_m2_en_courant,
           average_price_m2_nominal_euros = prix_moyen_annonce_au_m2_en_courant
           ) %>%
    mutate(locality = str_trim(locality)) %>%
    select(year, locality, n_offers, starts_with("average"))

}

```

```{r}
raw_data <- get_raw_data(url = "https://data.public.lu/fr/datasets/r/1d20f982-57e1-4ae2-a278-dc78c88c21dc")
```

Luxembourg is Luxembourg-ville in 2010 and 2011, then Luxembourg. Pétange is also spelled in two
ways also, converts make columns the right type. We also directly remove rows where the locality
contains information on the "Source". In the first version of the document this was done later
as we didn't know these rows where in there:

```{r function-clean_raw_data}
#' clean_raw_data Cleans the raw data
#'
#' @param url Optional: Persistent url to the data
#' @details Removes uneeded rows, renames localities to make their names consistent across years and converts columns with prices to numeric columns
#' @return A data frame
#' @export
clean_raw_data <- function(raw_data){
  raw_data %>%
    mutate(locality = ifelse(grepl("Luxembourg-Ville", locality),
                             "Luxembourg",
                             locality),
           locality = ifelse(grepl("P.tange", locality),
                             "Pétange",
                             locality)
           ) %>%
    filter(!grepl("Source", locality)) %>%
    mutate(across(starts_with("average"), as.numeric))
}
```

```{r}
flat_data <- clean_raw_data(raw_data)
```

We now need to make sure that we got all the communes/localities in there. There were mergers in
2011, 2015 and 2018. So we need to account for these localities.

We’re now scraping data from wikipedia of former Luxembourguish communes:

```{r function-get_former_communes}
#' get_former_communes Downloads list of former communes from Wikipedia
#'
#' @param url Optional: Persistent url to the data
#' @param min_year Optional: Minimum year to consider. Defaults to 2009 because price data starts in 2010
#' @param table_position Optional: Scraping returns a list of tables, so users need to specify the correct table. Defaults to 3, the position of the table as of writing.
#' @return A data frame
#' @export
get_former_communes <- function(url = "https://en.wikipedia.org/wiki/Communes_of_Luxembourg#Former_communes",
                                min_year = 2009,
                                table_position = 3)

  read_html(url) %>%
    html_table() %>%
    pluck(table_position) %>%
    clean_names() %>%
    filter(year_dissolved > min_year)

```

```{r}
former_communes <- get_former_communes()
```

We can scrape current communes:

```{r function-get_current_communes}
#' get_current_communes Downloads list of current communes from Wikipedia
#'
#' @param url Optional: Persistent url to the data
#' @param table_position Optional: Scraping returns a list of tables, so users need to specify the correct table. Defaults to 1, the position of the table as of writing.
#' @return A data frame
#' @export

get_current_communes <- function(url = "https://en.wikipedia.org/wiki/List_of_communes_of_Luxembourg",
                                 table_position = 1){
  read_html(url) %>%
    html_table() %>%
    pluck(table_position) %>%
    clean_names()
}

```

```{r}
current_communes <- get_current_communes()
```

Let’s now create a list of all communes:

```{r function-get_test_communes}
#' get_test_communes Creates list of communes that should be in the data
#'
#' @param former_communes Former communes df as returned by get_former_communes()
#' @param current_communes Current communes df as returned by get_current_communes()
#' @return A data frame
#' @export

get_test_communes <- function(former_communes, current_communes){

  communes <- unique(c(former_communes$name, current_communes$commune))
  # we need to rename some communes

  # Different spelling of these communes between wikipedia and the data

  communes[which(communes == "Clemency")] <- "Clémency"
  communes[which(communes == "Redange")] <- "Redange-sur-Attert"
  communes[which(communes == "Erpeldange-sur-Sûre")] <- "Erpeldange"
  communes[which(communes == "Luxembourg-City")] <- "Luxembourg"
  communes[which(communes == "Käerjeng")] <- "Kaerjeng"
  communes[which(communes == "Petange")] <- "Pétange"

  communes
}

```

```{r}
former_communes <- get_former_communes()
current_communes <- get_current_communes()

communes <- get_test_communes(former_communes, current_communes)
```


```{r tests-clean_flat_data}
# We now need to check if we have them all in the data. The test needs to be self-contained, hence
# why we need to redefine the required variables:
former_communes <- get_former_communes()
current_communes <- get_current_communes()

communes <- get_test_communes(former_communes, current_communes)

raw_data <- get_raw_data(url = "https://data.public.lu/fr/datasets/r/1d20f982-57e1-4ae2-a278-dc78c88c21dc")

flat_data <- clean_raw_data(raw_data)

testthat::expect_true(
            all(communes %in% unique(flat_data$locality))
                      )
```

Let’s keep the national average in another dataset:

```{r function-make_country_level_data}
#' make_country_level_data Makes the final data at country level
#'
#' @param flat_data Flat data df as returned by clean_flat_data()
#' @return A data frame
#' @export
make_country_level_data <- function(flat_data){
  country_level <- flat_data %>%
    filter(grepl("nationale", locality)) %>%
    select(-n_offers)

  offers_country <- flat_data %>%
    filter(grepl("Total d.offres", locality)) %>%
    select(year, n_offers)

  full_join(country_level, offers_country) %>%
    select(year, locality, n_offers, everything()) %>%
    mutate(locality = "Grand-Duchy of Luxembourg")

}

```

```{r}
country_level_data <- make_country_level_data(flat_data)
```

We can finish cleaning the commune data:

```{r function-make_commune_level_data}
#' make_commune_level_data Makes the final data at commune level
#'
#' @param flat_data Flat data df as returned by clean_flat_data()
#' @return A data frame
#' @export
make_commune_level_data <- function(flat_data){
  flat_data %>%
    filter(!grepl("nationale|offres", locality),
           !is.na(locality))
}

```

```{r}
commune_level_data <- make_commune_level_data(flat_data)
```

```{r}
usethis::use_data(commune_level_data, overwrite = TRUE)
usethis::use_data(country_level_data, overwrite = TRUE)
usethis::use_data(communes, overwrite = TRUE)
```

```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "minimal/save_data.qmd", vignette_name = "Saving the data", overwrite = T)
```
